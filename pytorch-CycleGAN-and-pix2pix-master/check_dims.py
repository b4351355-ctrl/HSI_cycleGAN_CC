import os
import glob
import scipy.io as sio
from PIL import Image
from collections import defaultdict
import numpy as np
from tqdm import tqdm  # å¦‚æœæ²¡æœ‰å®‰è£…tqdmï¼Œå¯ä»¥å»æ‰è¿™è¡Œå’Œä¸‹é¢çš„tqdm()åŒ…è£¹


def check_dataset_dimensions(dataroot):
    # å®šä¹‰å››ä¸ªå­æ–‡ä»¶å¤¹åŠå…¶å¯¹åº”çš„æ–‡ä»¶ç±»å‹
    phases = {
        'trainA': '.mat',
        'trainB': '.jpg',
        'testA': '.mat',
        'testB': '.jpg'
    }

    print(f"ğŸš€ å¼€å§‹æ£€æŸ¥æ•°æ®é›†è·¯å¾„: {dataroot}")
    print("=" * 60)

    # éå†æ¯ä¸ªé˜¶æ®µ (trainA, trainB, testA, testB)
    for phase_name, ext in phases.items():
        dir_path = os.path.join(dataroot, phase_name)

        # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
        if not os.path.exists(dir_path):
            print(f"âš ï¸  è­¦å‘Š: ç›®å½•ä¸å­˜åœ¨ {dir_path}ï¼Œè·³è¿‡ã€‚")
            print("-" * 60)
            continue

        print(f"ğŸ“‚ æ­£åœ¨æ£€æŸ¥ {phase_name} (æ–‡ä»¶ç±»å‹: {ext}) ...")

        # æŸ¥æ‰¾æ‰€æœ‰æ–‡ä»¶ (æ”¯æŒé€’å½’æŸ¥æ‰¾å­æ–‡ä»¶å¤¹)
        files = sorted(glob.glob(os.path.join(dir_path, '**', '*' + ext), recursive=True))

        if len(files) == 0:
            print(f"   âŒ æœªåœ¨è¯¥ç›®å½•ä¸‹æ‰¾åˆ° {ext} æ–‡ä»¶ï¼")
            print("-" * 60)
            continue

        # å­—å…¸ç”¨äºè®°å½•: å°ºå¯¸ -> [æ–‡ä»¶è·¯å¾„åˆ—è¡¨]
        size_counter = defaultdict(list)

        # ä½¿ç”¨ tqdm æ˜¾ç¤ºè¿›åº¦æ¡ (å¦‚æœæŠ¥é”™å°±æŠŠ tqdm(files) æ”¹æˆ files)
        for file_path in tqdm(files, desc="Scanning"):
            try:
                # --- å¤„ç† .mat æ–‡ä»¶ (é«˜å…‰è°±) ---
                if ext == '.mat':
                    mat = sio.loadmat(file_path)
                    if 'data' not in mat:
                        print(f"   âŒ é”™è¯¯: {os.path.basename(file_path)} ä¸­æ²¡æœ‰ 'data' é”®")
                        continue
                    data = mat['data']

                    # æ‚¨çš„æ•°æ®é€šå¸¸æ˜¯ (Channels, Height, Width) -> å– H, W
                    # ä¸ºäº†å…¼å®¹æ€§ï¼Œåˆ¤æ–­ä¸€ä¸‹ç»´åº¦
                    if data.ndim == 3:
                        # å‡è®¾æ ¼å¼ä¸º (C, H, W)
                        h, w = data.shape[1], data.shape[2]
                    elif data.ndim == 2:
                        h, w = data.shape[0], data.shape[1]
                    else:
                        print(f"   â“ æœªçŸ¥ç»´åº¦ {data.shape}: {os.path.basename(file_path)}")
                        continue

                    size = (h, w)

                # --- å¤„ç† .jpg æ–‡ä»¶ (RGB) ---
                elif ext == '.jpg':
                    with Image.open(file_path) as img:
                        w_pil, h_pil = img.size  # PIL è¿”å›çš„æ˜¯ (Width, Height)
                        size = (h_pil, w_pil)  # ç»Ÿä¸€è½¬æ¢ä¸º (Height, Width) ä»¥ä¾¿å¯¹æ¯”

                # è®°å½•è¯¥å°ºå¯¸
                size_counter[size].append(file_path)

            except Exception as e:
                print(f"   âŒ è¯»å–å¤±è´¥ {os.path.basename(file_path)}: {e}")

        # --- è¾“å‡ºç»Ÿè®¡ç»“æœ ---
        distinct_sizes = list(size_counter.keys())
        total_files = len(files)

        if len(distinct_sizes) == 1:
            h, w = distinct_sizes[0]
            print(f"   âœ… å®Œç¾ï¼æ‰€æœ‰ {total_files} ä¸ªæ–‡ä»¶å°ºå¯¸ä¸€è‡´: é«˜={h}, å®½={w}")
        else:
            print(f"   âš ï¸  æ³¨æ„ï¼å‘ç° {len(distinct_sizes)} ç§ä¸åŒçš„å°ºå¯¸ï¼š")
            # æŒ‰æ•°é‡ä»å¤šåˆ°å°‘æ’åº
            sorted_sizes = sorted(distinct_sizes, key=lambda s: len(size_counter[s]), reverse=True)

            for size in sorted_sizes:
                count = len(size_counter[size])
                ratio = count / total_files * 100
                print(f"      - å°ºå¯¸ {size[0]}x{size[1]}: {count} å¼  ({ratio:.1f}%)")

                # å¦‚æœè¿™ç§å°ºå¯¸çš„æ–‡ä»¶å¾ˆå°‘ï¼ˆå°‘äº10ä¸ªï¼‰ï¼Œå¾ˆå¯èƒ½æ˜¯å¼‚å¸¸å€¼ï¼Œæ‰“å°å‡ºæ¥æ–¹ä¾¿ä½ åˆ é™¤
                if count < 10:
                    print(f"        â””â”€â”€ æ–‡ä»¶å: {[os.path.basename(p) for p in size_counter[size]]}")

        print("-" * 60)


if __name__ == "__main__":
    # ğŸ”´ è¯·åœ¨è¿™é‡Œä¿®æ”¹ä¸ºæ‚¨æ•°æ®é›†çš„å®é™…æ ¹ç›®å½•
    target_dataroot = "./datasets/cyclegan_dataset_HSI"

    check_dataset_dimensions(target_dataroot)